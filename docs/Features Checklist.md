# Features Checklist

This checklist prioritizes features (P0-P3) grouping them by parent page/module, considering core user value and a logical development flow.

## Priority Legend:

*   **P0: Must-Have (Core MVP)** - Absolutely necessary features to launch the product and demonstrate its core value.
*   **P1: High Priority** - Very important features that complete the core offering and address key user needs soon after launch.
*   **P2: Medium Priority** - Useful features improving the experience or adding significant value, but can wait for a later iteration.
*   **P3: Low Priority** - "Nice-to-have", advanced, or less critical features for the initial launch.
*   **Status:** Indicated at the end of each line. The LLM and human operator should adjust the status after their manipulations. `[Backlog]` `[To Do]` `[In Progress]` `[Test]` `[In Review]` `[Done]`


---

## 1. Core Build Lifecycle

### Feature: API Endpoint for Build Initiation (`POST /builds`) - P0 [Done]

- Done Criteria:
  - Endpoint accepts JSON payload: `target_urls` (array of strings), `user_objective` (string).
  - Performs input validation (URL format, non-empty objective/URLs).
  - Performs Authentication/Authorization (e.g., API Key).
  - Generates and stores a unique `build_id` record with initial status `pending_analysis`.
  - Successfully triggers the asynchronous backend LLM analysis process, passing `build_id`, `target_urls`, and `user_objective`.
  - Returns `202 Accepted` response with `build_id` and initial status (e.g., `processing` or `analyzing`).
  - Handles auth failures and basic validation errors with appropriate HTTP status codes (400, 401/403).

### Feature: LLM Analysis & Initial Tool Selection (Internal Process) - P0 [To Do]

- Done Criteria:
  - Backend process receives build request data (`build_id`, URLs, objective).
  - LLM analyzes the objective and sample target URLs (fetching initial content if needed).
  - LLM determines the required data fields based on the objective.
  - LLM selects an appropriate initial set of tools (e.g., specific scraper module/method, base anti-blocking strategy, proxy type if required) from a predefined, available toolbox.
  - LLM generates the initial parameters or configurations required for the selected tools to target the desired data fields.
  - This initial tool configuration (the "package") is stored temporarily, associated with the `build_id`.
  - Triggers the "Initial Sample Generation" process using this package.
  - Updates build status (e.g., to `generating_samples`).
  - Handles LLM analysis failures (e.g., cannot understand objective, cannot identify tools) by updating build status to `failed` with an appropriate error message.

### Feature: Modular Tool Integration & Execution Framework - P0 [To Do]

- Done Criteria:
  - Define a standard internal interface or contract (e.g., TypeScript interface) for different scraping tools (e.g., Playwright script class, Cheerio/DOM parser function, specific API client).
  - Define standard interfaces for auxiliary tools (e.g., proxy managers, anti-captcha services, user-agent rotators).
  - Implement a core execution engine capable of loading and running the selected tools based on a standardized configuration package format.
  - Ensure tools can be invoked with specific parameters (URLs, selectors, credentials, proxy settings) defined in the configuration package.
  - Ensure tools return results (or errors) in a standardized format (e.g., defined TypeScript types) that the core engine can capture.

### Feature: Initial Sample Generation (Internal Process) - P0 [To Do]

- Done Criteria:
  - Backend process uses the "Modular Tool Integration & Execution Framework" to run the initially selected tool package (from "LLM Analysis & Initial Tool Selection").
  - Executes the package against a small subset of the provided `target_urls`.
  - Captures the structured JSON output (or errors) for each sample URL processed.
  - Stores these sample results (`package_results`) associated with the `build_id`.
  - Updates the build status to `pending_user_feedback` upon successful sample generation.
  - Handles failures during sample generation (e.g., tool errors, sites blocking) by updating build status to `failed` with specific error details.

### Feature: API Endpoint for Build Status & Samples (`GET /builds/{build_id}`) - P0 [To Do]

- Done Criteria:
  - Endpoint accepts `build_id` via path parameter.
  - Performs Authentication/Authorization.
  - Returns current build status (e.g., `processing`, `generating_samples`, `pending_user_feedback`, `failed`, `confirmed`).
  - If status is `pending_user_feedback`, response includes the stored `package_results` array containing valid JSON sample data generated by the initial package.
  - Handles `build_id` not found (404).
  - Handles auth failures (401/403).
  - Response structure is consistent.

### Feature: API Endpoint for Build Refinement/Feedback (`POST /builds/{build_id}/configure`) - P1 [Backlog]

- Done Criteria:
  - Endpoint accepts `build_id` via path parameter.
  - Accepts JSON payload with `user_feedback` (string) and optional `tool_hints`.
  - Performs Authentication/Authorization.
  - Validates that the build is in a state accepting feedback (e.g., `pending_user_feedback`).
  - Successfully triggers the asynchronous backend LLM refinement process, passing the `build_id`, original objective/URLs, previous tool package, sample results, and new user feedback.
  - Updates the build status (e.g., `processing_feedback`).
  - Returns `202 Accepted` response.
  - Handles `build_id` not found (404).
  - Handles invalid state errors (e.g., trying to configure a confirmed build) (409 Conflict or 400).
  - Handles auth failures (401/403).

### Feature: LLM Package Refinement & Tool Switching (Internal Process) - P1 [Backlog]

- Done Criteria:
  - Backend refinement process receives build context and user feedback.
  - LLM analyzes the feedback in context of the previous results and objective.
  - **(Integration Point):** Incorporates relevant insights/configurations retrieved from the "**Knowledge Base - Leverage Past Configurations**" feature (if enabled and relevant matches found).
  - LLM modifies the existing tool configuration *or* selects different tools from the toolbox based on the feedback (leveraging the modular framework). This might involve changing scraper logic, adjusting anti-blocking, switching proxy types, etc.
  - Generates a *new* refined configuration package.
  - Stores the *new*, refined tool configuration package temporarily, associated with the `build_id`, replacing the previous one.
  - **(Next Step):** Triggers the "Configuration Package Sanity Check" process (if implemented) OR directly triggers the "Initial Sample Generation" process.
  - Updates build status appropriately (e.g., `validating_config` or `generating_samples`).
  - Handles LLM failures during refinement (e.g., cannot interpret feedback) by updating status to `failed`.

### Feature: Configuration Package Sanity Check (Internal Process - Optional Enhancement) - P2/P3 [Backlog]

- Done Criteria:
  - **Trigger:** Executes immediately after `LLM Package Refinement` generates a new temporary configuration package.
  - Validates the generated package against the defined **Universal Configuration Package Format** schema.
  - Verifies that all tools specified in the package exist in the system's available **Toolbox**.
  - **(Outcome):** If validation passes, proceeds to trigger "**Initial Sample Generation**".
  - **(Outcome):** If validation fails, updates the build status to `failed` with a specific error (e.g., "Internal Error: Invalid configuration package generated") and prevents the sample generation attempt.
  - Adds minimal processing overhead.

### Feature: Universal Configuration Package Format (Internal Definition) - P0 [To Do]

- Done Criteria:
  - Define a standardized JSON schema (or similar format, like TypeScript types/interfaces for validation) for representing a complete "Scraper Configuration Package".
  - This format must be capable of specifying:
    - The chosen primary scraper tool (e.g., "playwright_v1", "cheerio_parser_v2").
    - Parameters for the scraper (e.g., target selectors, data extraction logic/mapping, interaction steps).
    - Selected auxiliary tools (e.g., "proxy_manager_smart", "captcha_solver_2captcha").
    - Parameters for auxiliary tools (e.g., proxy geo-location, API keys).
    - Expected output schema/structure (optional, could be inferred).
  - This format is generated by the LLM (during initial selection and refinement).
  - This format is consumed by the "Modular Tool Integration & Execution Framework" to run builds and full scrapes.
  - This format is what gets saved as the `final_configuration` upon confirmation.

### Feature: API Endpoint for Build Confirmation (`POST /builds/{build_id}/confirm`) - P0 [To Do]

- Done Criteria:
  - Endpoint accepts `build_id` via path parameter.
  - Performs Authentication/Authorization.
  - Validates that the build is in a confirmable state (e.g., `pending_user_feedback`).
  - Retrieves the *current* temporary tool configuration package (in the Universal Configuration Package Format) associated with the latest successful samples for this build.
  - Persistently stores this package as the `final_configuration`.
  - Updates the build status to `confirmed`.
  - Returns `200 OK` response.
  - Handles `build_id` not found (404).
  - Handles invalid state errors (409 Conflict or 400).
  - Handles auth failures (401/403).

### Feature: Error Reporting for Failed Builds (`GET /builds/{build_id}`) - P0 [To Do]

- Done Criteria:
  - When a build process fails (during LLM analysis, sample generation, refinement, or sanity check), its status is updated to `failed`.
  - The `GET /builds/{build_id}` endpoint returns `status: failed` for such builds.
  - The response includes a clear, user-understandable `error` field explaining the reason (e.g., "Objective unclear", "Samples failed: Target site blocked", "Refinement failed: Feedback contradictory", "Internal Error: Invalid configuration package generated").

------

## 2. Core Run Lifecycle

### Feature: API Endpoint for Run Execution (`POST /runs`) - P0 [To Do]

- Done Criteria:
  - Endpoint accepts JSON payload: `build_id`, `target_urls` (array of strings).
  - Performs Authentication/Authorization.
  - Validates that the referenced `build_id` exists and is in `confirmed` state.
  - Retrieves the stored `final_configuration` (in Universal Package Format) for the `build_id`.
  - Validates `target_urls` format.
  - Generates and stores a unique `run_id`.
  - Successfully triggers the asynchronous full scraping process, passing the `run_id`, `target_urls`, and the `final_configuration` to the execution engine.
  - Returns `202 Accepted` response with `run_id` and initial status (e.g., `pending`, `running`).
  - Handles validation errors (invalid `build_id`, non-confirmed state, bad URLs) (400, 404).
  - Handles auth failures (401/403).

### Feature: Full Scrape Execution Engine (Internal Process) - P0 [To Do]

- Done Criteria:
  - Backend process receives `run_id`, `target_urls`, and `final_configuration`.
  - Uses the "Modular Tool Integration & Execution Framework" to execute the specified configuration package against *all* provided `target_urls`.
  - Manages parallel execution (scaling workers based on URL count/system load).
  - Handles transient errors (e.g., network timeouts, temporary blocks) with appropriate retry logic configured within the framework or package.
  - Aggregates results (successful JSON outputs and any persistent errors per URL).
  - Updates run status periodically (e.g., `running` with progress) and finally to `completed` or `failed`.
  - Stores the aggregated results associated with the `run_id`.

### Feature: API Endpoint for Run Status (`GET /runs/{run_id}`) - P0 [To Do]

- Done Criteria:
  - Endpoint accepts `run_id` via path parameter.
  - Performs Authentication/Authorization.
  - Returns current run status (`pending`, `running`, `completed`, `failed`, `canceled`).
  - (P1 enhancement): If `running`, includes progress metrics (e.g., `progress_percent`, `urls_processed`, `urls_total`, `errors_encountered`).
  - Handles `run_id` not found (404).
  - Handles auth failures (401/403).

### Feature: API Endpoint for Run Results Retrieval (`GET /runs/{run_id}/results`) - P0 [To Do]

- Done Criteria:
  - Endpoint accepts `run_id` via path parameter.
  - Performs Authentication/Authorization.
  - Validates that the run status is `completed` (or perhaps `failed` if partial results are enabled).
  - Returns `200 OK` response containing the array of structured JSON results (and potentially per-URL errors if applicable).
  - Handles `run_id` not found (404).
  - Handles cases where the run is not `completed` (e.g., return status or appropriate error 409/400).
  - Handles auth failures (401/403).
  - (P2/P3 Consideration): Implement pagination (`limit`, `offset` params) for large result sets.

### Feature: Error Reporting for Failed Runs (`GET /runs/{run_id}`) - P0 [To Do]

- Done Criteria:
  - When a run process fails (e.g., critical tool error, excessive URL failures), its status is updated to `failed`.
  - The `GET /runs/{run_id}` endpoint returns `status: failed` for such runs.
  - The response includes a clear, user-understandable `error` field detailing the overall failure reason (e.g., "Run failed: >50% URLs resulted in errors", "Critical component failure: Proxy Manager").
  - (P1 Requirement): Define and implement policy on whether `GET /runs/{run_id}/results` should return partial data for failed runs.

### Feature: API Endpoint for Run Cancellation (`POST /runs/{run_id}/cancel` or `DELETE /runs/{run_id}`) - P1 [Backlog]

- Done Criteria:
  - Endpoint accepts `run_id` via path parameter.
  - Performs Authentication/Authorization.
  - Validates that the run exists and is in the `running` state.
  - Successfully sends a termination signal to the backend execution engine managing that run.
  - Returns `202 Accepted` response immediately.
  - Backend attempts graceful shutdown of running workers for the run; run status is eventually updated to `canceled`.
  - Handles `run_id` not found (404).
  - Handles invalid state errors (e.g., trying to cancel a completed run) (409 Conflict or 400).
  - Handles auth failures (401/403).

------

## 3. Learning / Knowledge Base Features

### Feature: Knowledge Base - Save Successful Configuration Package - P2 [Backlog]

- Done Criteria:
  - Process triggers automatically and successfully upon `POST /builds/{id}/confirm`.
  - Correctly extracts/derives `final_configuration` (in Universal Package Format), `platform_identifiers`, and `output_schema` from the confirmed build context.
  - Optionally captures/embeds `user_objective`.
  - Stores the captured data reliably in the designated knowledge base DB (e.g., Vector DB + Structured DB).
  - Ensures the stored data is indexed appropriately for later retrieval based on platform, schema, and objective similarity.
  - Saving process adds minimal latency to the user's confirmation request.
  - Failures during saving are logged but do not prevent the build confirmation from succeeding for the user.

### Feature: Knowledge Base - Leverage Past Configuration Packages - P2 [Backlog]

- Done Criteria:

  - Process triggers automatically at the start of a new `POST /builds` request processing (before "LLM Analysis & Initial Tool Selection").

  - Successfully queries the knowledge base using criteria derived from the new request (platform, objective, etc.).

  - Implements logic to rank and select relevant results from the knowledge base.

  - Implements logic to

     

    either

    :

    - Directly use a high-confidence matched configuration package as the initial package for "Initial Sample Generation" (*fast path*), OR
    - Provide retrieved example packages as context to the "LLM Analysis & Initial Tool Selection" process or the "LLM Package Refinement" process.

  - Logs whether and how past knowledge was used for a given build.

  - Knowledge base lookup adds acceptable latency to the overall build initiation phase.

  - Requires "Knowledge Base - Save Successful Configuration Package" feature to be functional.

------

## 4. System Transparency & Manual Control Features

### Feature: API Endpoint for Tool Discovery (`GET /tools`) - P1 [Backlog]

- Done Criteria:
  - Endpoint is publicly accessible (or requires standard auth).
  - Returns a list (`200 OK`) of all available tools (scrapers, anti-blocking methods, proxy managers, etc.) managed by the "Modular Tool Integration & Execution Framework".
  - Each tool entry includes:
    - `tool_id` (unique identifier used in the Universal Configuration Package Format).
    - `tool_name` (human-readable name).
    - `tool_type` (e.g., "scraper", "proxy", "captcha_solver").
    - Brief `description` of its function/use case.
    - (Optional P2 Enhancement): Expected parameters/schema for the tool's configuration block within the Universal Configuration Package Format.

### Feature: API Endpoint for Manual Build (`POST /builds/manual`) - P2 [Backlog]

- Done Criteria:
  - Endpoint accepts a JSON payload containing a complete scraper configuration package defined in the **Universal Configuration Package Format**.
  - Requires Authentication/Authorization.
  - Validates the provided configuration package against the Universal Configuration Package Format schema (similar to the "Configuration Package Sanity Check").
  - Validates that all specified tools exist in the Toolbox.
  - If valid, generates a unique `build_id`, stores the provided configuration package as the *initial* temporary package, and sets status (e.g. `manual_config_provided`).
  - Triggers the "Initial Sample Generation" process using the *manually provided* package and a predefined set of sample URLs (or requires sample URLs in the request).
  - Returns `202 Accepted` with the `build_id`.
  - Allows users to bypass the LLM analysis/refinement loop for direct configuration testing or use cases where the LLM struggles. Build proceeds directly to user confirmation (`POST /builds/{id}/confirm`) after samples are reviewed via `GET /builds/{id}`.